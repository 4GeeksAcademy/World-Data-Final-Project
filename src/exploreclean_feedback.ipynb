{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Title goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Problem Definition\n",
    "**<span style=\"color:red;\">TODO:</span> @Nicholas, @Logan define your objective/problem definition here. Here are some questions you should consider:**\n",
    "\n",
    "1. **Business Objective**: What is the business problem you want to solve? What is the overarching goal or objective of the project?\n",
    "\n",
    "2. **Problem Type**: What type of problem are you trying to solve? Is it a regression problem (predicting a continuous value), classification problem (assigning labels to instances), clustering problem (grouping similar instances together), time series forecasting (predicting future values based on past observations), or something else?\n",
    "\n",
    "3. **Stakeholders**: Who are the stakeholders or end users of the solution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Acquiring and loading the data set\n",
    "**<span style=\"color:red;\">TODO:</span> @Nicholas, @Logan you should provide some context about your dataset. Here are some questions you should consider:**\n",
    "\n",
    "1. **Source of the Data:** Where did the dataset come from? Is it publicly available data, data from a specific research project, or data from a company or organization?\n",
    "\n",
    "2. **Variables and Features:** What do each of the columns represent? For example:\n",
    "- `Model`: The make and model of the vehicle\n",
    "- `Displ`: Engine displacement in liters.\n",
    "- ...\n",
    "\n",
    "3. **Data Collection**: How did you collect the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import data\n",
    "total_data2024 = pd.read_excel(\"../data/raw/all_alpha_24.xlsx\")\n",
    "total_data2023 = pd.read_excel(\"../data/raw/all_alpha_23.xlsx\")\n",
    "total_data2022 = pd.read_excel(\"../data/raw/all_alpha_22.xlsx\")\n",
    "total_data2021 = pd.read_excel(\"../data/raw/all_alpha_21.xlsx\")\n",
    "total_data2020 = pd.read_excel(\"../data/raw/all_alpha_20.xlsx\")\n",
    "total_data2019 = pd.read_excel(\"../data/raw/all_alpha_19.xlsx\")\n",
    "total_data2018 = pd.read_excel(\"../data/raw/all_alpha_18.xlsx\")\n",
    "total_data2017 = pd.read_excel(\"../data/raw/all_alpha_17.xlsx\")\n",
    "total_data2016 = pd.read_excel(\"../data/raw/all_alpha_16.xlsx\")\n",
    "total_data2015 = pd.read_excel(\"../data/raw/all_alpha_15.xlsx\")\n",
    "total_data2014 = pd.read_excel(\"../data/raw/all_alpha_14.xlsx\")\n",
    "total_data2013 = pd.read_excel(\"../data/raw/all_alpha_13.xlsx\")\n",
    "total_data2012 = pd.read_excel(\"../data/raw/all_alpha_12.xlsx\")\n",
    "total_data2011 = pd.read_excel(\"../data/raw/all_alpha_11.xlsx\")\n",
    "total_data2010 = pd.read_excel(\"../data/raw/all_alpha_10.xls\")\n",
    "total_data2009 = pd.read_excel(\"../data/raw/all_alpha_09.xls\")\n",
    "total_data2008 = pd.read_excel(\"../data/raw/all_alpha_08.xls\")\n",
    "total_data2007 = pd.read_excel(\"../data/raw/all_alpha_07.xls\")\n",
    "total_data2006 = pd.read_excel(\"../data/raw/all_alpha_06.xls\")\n",
    "total_data2005 = pd.read_excel(\"../data/raw/all_alpha_05.xls\")\n",
    "total_data2004 = pd.read_excel(\"../data/raw/all_alpha_04.xls\")\n",
    "total_data2003 = pd.read_excel(\"../data/raw/all_alpha_03.xls\")\n",
    "total_data2002 = pd.read_excel(\"../data/raw/all_alpha_02.xls\")\n",
    "total_data2001 = pd.read_excel(\"../data/raw/all_alpha_01.xls\")\n",
    "total_data2000 = pd.read_excel(\"../data/raw/all_alpha_00 (1).xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#Add year to each data set as a column\n",
    "\n",
    "total_data2024['Year'] = 2024\n",
    "total_data2023['Year'] = 2023\n",
    "total_data2022['Year'] = 2022\n",
    "total_data2021['Year'] = 2021\n",
    "total_data2020['Year'] = 2020\n",
    "total_data2019['Year'] = 2019\n",
    "total_data2018['Year'] = 2018\n",
    "total_data2017['Year'] = 2017\n",
    "total_data2016['Year'] = 2016\n",
    "total_data2015['Year'] = 2015\n",
    "total_data2014['Year'] = 2014\n",
    "total_data2013['Year'] = 2013\n",
    "total_data2012['Year'] = 2012\n",
    "total_data2011['Year'] = 2011\n",
    "total_data2010['Year'] = 2010\n",
    "total_data2009['Year'] = 2009\n",
    "total_data2008['Year'] = 2008\n",
    "total_data2007['Year'] = 2007\n",
    "total_data2006['Year'] = 2006\n",
    "total_data2005['Year'] = 2005\n",
    "total_data2004['Year'] = 2004\n",
    "total_data2003['Year'] = 2003\n",
    "total_data2002['Year'] = 2002\n",
    "total_data2001['Year'] = 2001\n",
    "total_data2000['Year'] = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#merge all datasets into one\n",
    "merged_data = pd.concat([total_data2024, total_data2023, total_data2022, total_data2021, total_data2020, \n",
    "                         total_data2019, total_data2018, total_data2017, total_data2016, total_data2015, \n",
    "                         total_data2014, total_data2013, total_data2012, total_data2011, total_data2010, \n",
    "                         total_data2009, total_data2008, total_data2007, total_data2006, total_data2005, \n",
    "                         total_data2004, total_data2003, total_data2002, total_data2001, total_data2000], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Displ</th>\n",
       "      <th>Cyl</th>\n",
       "      <th>Trans</th>\n",
       "      <th>Drive</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Cert Region</th>\n",
       "      <th>Stnd</th>\n",
       "      <th>Stnd Description</th>\n",
       "      <th>Underhood ID</th>\n",
       "      <th>...</th>\n",
       "      <th>City MPG</th>\n",
       "      <th>Hwy MPG</th>\n",
       "      <th>Cmb MPG</th>\n",
       "      <th>Greenhouse Gas Score</th>\n",
       "      <th>SmartWay</th>\n",
       "      <th>Comb CO2</th>\n",
       "      <th>Year</th>\n",
       "      <th>Sales Area</th>\n",
       "      <th>FE Calc Appr</th>\n",
       "      <th>Unadj Cmb MPG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACURA Integra</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SCV-7</td>\n",
       "      <td>2WD</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>CA</td>\n",
       "      <td>L3SULEV30</td>\n",
       "      <td>California LEV-III SULEV30</td>\n",
       "      <td>RHNXV01.54EC</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>No</td>\n",
       "      <td>269</td>\n",
       "      <td>2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACURA Integra</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SCV-7</td>\n",
       "      <td>2WD</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>FA</td>\n",
       "      <td>T3B30</td>\n",
       "      <td>Federal Tier 3 Bin 30</td>\n",
       "      <td>RHNXV01.54EC</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>No</td>\n",
       "      <td>269</td>\n",
       "      <td>2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACURA Integra</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Man-6</td>\n",
       "      <td>2WD</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>CA</td>\n",
       "      <td>L3ULEV50</td>\n",
       "      <td>California LEV-III ULEV50</td>\n",
       "      <td>RHNXV02.0TDC</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>371</td>\n",
       "      <td>2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACURA Integra</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Man-6</td>\n",
       "      <td>2WD</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>FA</td>\n",
       "      <td>T3B50</td>\n",
       "      <td>Federal Tier 3 Bin 50</td>\n",
       "      <td>RHNXV02.0TDC</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>371</td>\n",
       "      <td>2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACURA Integra A-Spec</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Man-6</td>\n",
       "      <td>2WD</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>CA</td>\n",
       "      <td>L3ULEV50</td>\n",
       "      <td>California LEV-III ULEV50</td>\n",
       "      <td>RHNXV01.55DC</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>No</td>\n",
       "      <td>293</td>\n",
       "      <td>2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58440</th>\n",
       "      <td>VOLVO V70</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Auto-L4</td>\n",
       "      <td>4WD</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LEV</td>\n",
       "      <td>LEV</td>\n",
       "      <td>YVVXV2.43PA3</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>NF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58441</th>\n",
       "      <td>VOLVO V70</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Auto-L4</td>\n",
       "      <td>2WD</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LEV</td>\n",
       "      <td>LEV</td>\n",
       "      <td>YVVXV2.43PA3</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>NF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58442</th>\n",
       "      <td>VOLVO V70</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Auto-L5</td>\n",
       "      <td>2WD</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LEV</td>\n",
       "      <td>LEV</td>\n",
       "      <td>YVVXV2.43TF3</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>NF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58443</th>\n",
       "      <td>VOLVO V70</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Man-5</td>\n",
       "      <td>2WD</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LEV</td>\n",
       "      <td>LEV</td>\n",
       "      <td>YVVXV2.43TF3</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>NF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58444</th>\n",
       "      <td>WINNEBAGO H-Body</td>\n",
       "      <td>2.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2WD</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T1</td>\n",
       "      <td>TIER 1</td>\n",
       "      <td>YWBXT02.8225</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>CL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58445 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Displ  Cyl    Trans Drive      Fuel Cert Region  \\\n",
       "0             ACURA Integra    1.5  4.0    SCV-7   2WD  Gasoline          CA   \n",
       "1             ACURA Integra    1.5  4.0    SCV-7   2WD  Gasoline          FA   \n",
       "2             ACURA Integra    2.0  4.0    Man-6   2WD  Gasoline          CA   \n",
       "3             ACURA Integra    2.0  4.0    Man-6   2WD  Gasoline          FA   \n",
       "4      ACURA Integra A-Spec    1.5  4.0    Man-6   2WD  Gasoline          CA   \n",
       "...                     ...    ...  ...      ...   ...       ...         ...   \n",
       "58440             VOLVO V70    2.4  5.0  Auto-L4   4WD  Gasoline         NaN   \n",
       "58441             VOLVO V70    2.4  5.0  Auto-L4   2WD  Gasoline         NaN   \n",
       "58442             VOLVO V70    2.4  5.0  Auto-L5   2WD  Gasoline         NaN   \n",
       "58443             VOLVO V70    2.4  5.0    Man-5   2WD  Gasoline         NaN   \n",
       "58444      WINNEBAGO H-Body    2.8  NaN      NaN   2WD  Gasoline         NaN   \n",
       "\n",
       "            Stnd            Stnd Description  Underhood ID  ... City MPG  \\\n",
       "0      L3SULEV30  California LEV-III SULEV30  RHNXV01.54EC  ...       30   \n",
       "1          T3B30       Federal Tier 3 Bin 30  RHNXV01.54EC  ...       30   \n",
       "2       L3ULEV50   California LEV-III ULEV50  RHNXV02.0TDC  ...       21   \n",
       "3          T3B50       Federal Tier 3 Bin 50  RHNXV02.0TDC  ...       21   \n",
       "4       L3ULEV50   California LEV-III ULEV50  RHNXV01.55DC  ...       26   \n",
       "...          ...                         ...           ...  ...      ...   \n",
       "58440        LEV                         LEV  YVVXV2.43PA3  ...       16   \n",
       "58441        LEV                         LEV  YVVXV2.43PA3  ...       17   \n",
       "58442        LEV                         LEV  YVVXV2.43TF3  ...       18   \n",
       "58443        LEV                         LEV  YVVXV2.43TF3  ...       19   \n",
       "58444         T1                      TIER 1  YWBXT02.8225  ...      NaN   \n",
       "\n",
       "      Hwy MPG Cmb MPG Greenhouse Gas Score SmartWay Comb CO2  Year Sales Area  \\\n",
       "0          37      33                    6       No      269  2024        NaN   \n",
       "1          37      33                    6       No      269  2024        NaN   \n",
       "2          28      24                    5       No      371  2024        NaN   \n",
       "3          28      24                    5       No      371  2024        NaN   \n",
       "4          36      30                    6       No      293  2024        NaN   \n",
       "...       ...     ...                  ...      ...      ...   ...        ...   \n",
       "58440      23      19                    5       no      NaN  2000         NF   \n",
       "58441      24      20                    6       no      NaN  2000         NF   \n",
       "58442      26      21                    6       no      NaN  2000         NF   \n",
       "58443      26      22                    6       no      NaN  2000         NF   \n",
       "58444     NaN     NaN                  NaN       no      NaN  2000         CL   \n",
       "\n",
       "       FE Calc Appr Unadj Cmb MPG  \n",
       "0               NaN           NaN  \n",
       "1               NaN           NaN  \n",
       "2               NaN           NaN  \n",
       "3               NaN           NaN  \n",
       "4               NaN           NaN  \n",
       "...             ...           ...  \n",
       "58440           NaN           NaN  \n",
       "58441           NaN           NaN  \n",
       "58442           NaN           NaN  \n",
       "58443           NaN           NaN  \n",
       "58444           NaN           NaN  \n",
       "\n",
       "[58445 rows x 22 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Model', 'Displ', 'Cyl', 'Trans', 'Drive', 'Fuel', 'Cert Region',\n",
       "       'Stnd', 'Stnd Description', 'Underhood ID', 'Veh Class',\n",
       "       'Air Pollution Score', 'City MPG', 'Hwy MPG', 'Cmb MPG',\n",
       "       'Greenhouse Gas Score', 'SmartWay', 'Comb CO2', 'Year', 'Sales Area',\n",
       "       'FE Calc Appr', 'Unadj Cmb MPG'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows containing 'N/A*'\n",
    "merged_data = merged_data[~merged_data['City MPG'].astype(str).str.contains('N/A*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows containing 'nan'\n",
    "merged_data = merged_data[~merged_data['City MPG'].astype(str).str.contains('nan')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Convert \"Air Pollution Score\" column to string type\n",
    "merged_data[\"Air Pollution Score\"] = merged_data[\"Air Pollution Score\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#one row has Gasoline/Electricity and its values flipped (Ie 90/35 instead of 35/90), \n",
    "#this fixes that for the 'Fuel', 'City MPG', \"Hwy MPG', and 'Cmb MPG'\n",
    "def reverse_mpg_values(df):\n",
    "    # Filter rows where Fuel is 'Electricity/Gasoline'\n",
    "    filter_condition = df['Fuel'] == 'Electricity/Gasoline'\n",
    "    filtered_df = df[filter_condition].copy()\n",
    "\n",
    "    # Change 'Electricity/Gasoline' to 'Gasoline/Electricity'\n",
    "    filtered_df.loc[:, 'Fuel'] = 'Gasoline/Electricity'\n",
    "\n",
    "    # Check if columns exist before splitting\n",
    "    if 'City MPG' in filtered_df.columns:\n",
    "        # Reverse the 'City MPG' values\n",
    "        filtered_df[['Gasoline_City_MPG', 'Electricity_City_MPG']] = filtered_df['City MPG'].str.split('/', expand=True)\n",
    "        filtered_df['City MPG'] = filtered_df['Electricity_City_MPG'] + '/' + filtered_df['Gasoline_City_MPG']\n",
    "\n",
    "    if 'Hwy MPG' in filtered_df.columns:\n",
    "        # Reverse the 'Hwy MPG' values\n",
    "        filtered_df[['Gasoline_Hwy_MPG', 'Electricity_Hwy_MPG']] = filtered_df['Hwy MPG'].str.split('/', expand=True)\n",
    "        filtered_df['Hwy MPG'] = filtered_df['Electricity_Hwy_MPG'] + '/' + filtered_df['Gasoline_Hwy_MPG']\n",
    "\n",
    "    if 'Cmb MPG' in filtered_df.columns:\n",
    "        # Reverse the 'Cmb MPG' values\n",
    "        filtered_df[['Gasoline_Cmb_MPG', 'Electricity_Cmb_MPG']] = filtered_df['Cmb MPG'].str.split('/', expand=True)\n",
    "        filtered_df['Cmb MPG'] = filtered_df['Electricity_Cmb_MPG'] + '/' + filtered_df['Gasoline_Cmb_MPG']\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    columns_to_drop = ['Gasoline_City_MPG', 'Electricity_City_MPG', 'Gasoline_Hwy_MPG', 'Electricity_Hwy_MPG', \n",
    "                       'Gasoline_Cmb_MPG', 'Electricity_Cmb_MPG']\n",
    "    filtered_df.drop(columns_to_drop, axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "    # Update the original DataFrame with the modified values\n",
    "    df.update(filtered_df)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Call the function on your merged_data DataFrame\n",
    "merged_data = reverse_mpg_values(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#Fix names in 'Fuel' column to conform to a naming convention\n",
    "merged_data['Fuel'] = merged_data['Fuel'].replace('Gasoline/Electricty', 'Gasoline/Electricity')\n",
    "merged_data['Fuel'] = merged_data['Fuel'].replace('ethanol', 'Ethanol')\n",
    "merged_data['Fuel'] = merged_data['Fuel'].replace('diesel', 'Diesel')\n",
    "merged_data['Fuel'] = merged_data['Fuel'].replace('ethanol/gas', 'Ethanol/Gas')\n",
    "merged_data['Fuel'] = merged_data['Fuel'].replace('Ethonal/Gas', 'Ethanol/Gasoline')\n",
    "merged_data['Fuel'] = merged_data['Fuel'].replace('CNG/gas', 'CNG/Gasoline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#drop duplicates, ignoring the specified columns\n",
    "merged_data.drop_duplicates(subset=merged_data.columns.difference(['Cert Region', 'Stnd', 'Stnd Description', 'Sales Area']), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#split MODEL column into CAR_MAKE and CAR_MODEL\n",
    "\n",
    "def split_model(row):\n",
    "    if 'ASTON MARTIN' in row['Model']:\n",
    "        return 'ASTON MARTIN', row['Model'].replace('ASTON MARTIN ', '')\n",
    "    elif 'LAND ROVER' in row['Model']:\n",
    "        return 'LAND ROVER', row['Model'].replace('LAND ROVER ', '')\n",
    "    elif 'ALFA ROMEO' in row['Model']:\n",
    "        return 'ALFA ROMEO', row['Model'].replace('ALFA ROMEO ', '')\n",
    "    elif 'VEHICLE PRODUCTION GROUP' in row['Model']:\n",
    "        return 'VEHICLE PRODUCTION GROUP', row['Model'].replace('VEHICLE PRODUCTION GROUP ', '')\n",
    "    else:\n",
    "        return row['Model'].split(maxsplit=1)\n",
    "    \n",
    "#apply function split_model\n",
    "merged_data[['Car_Make', 'Car_Model']] = merged_data.apply(split_model, axis=1, result_type='expand')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Comb CO2 was already removed.\n"
     ]
    }
   ],
   "source": [
    "#columns to remove before pipeline\n",
    "\n",
    "columns_to_remove = ['Model', \n",
    "                     'Cert Region', \n",
    "                     'Comb CO2', \n",
    "                     'Stnd', \n",
    "                     'Stnd Description', \n",
    "                     'Underhood ID',  \n",
    "                     'Sales Area', \n",
    "                     'FE Calc Appr', \n",
    "                     'Unadj Cmb MPG', \n",
    "                     'Comb CO2',\n",
    "                     'SmartWay']\n",
    "\n",
    "for column in columns_to_remove:\n",
    "    try:\n",
    "        merged_data = merged_data.drop(column, axis=1)\n",
    "    except:\n",
    "        print(f\"Column {column} was already removed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#for cylinders, since electric cars don't have cylinders, we replace the nan value with their fuel type of Electric\n",
    "def handle_nan(row):\n",
    "    if pd.isna(row['Cyl']):\n",
    "        return row['Fuel']  # If NaN, copy value from 'Fuel' column\n",
    "    else:\n",
    "        return row['Cyl']  # Return the original value if not NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#fix naming conventions of cyl column\n",
    "def convert_cyl(row):\n",
    "    if row['Cyl'] == '(6 cyl)':\n",
    "        return 6.0\n",
    "    elif row['Cyl'] == '(4 cyl)':\n",
    "        return 4.0\n",
    "    elif row['Cyl'] == '(12 cyl)':\n",
    "        return 12.0\n",
    "    elif row['Cyl'] == '(8 cyl)':\n",
    "        return 8.0\n",
    "    elif row['Cyl'] == '(10 cyl)':\n",
    "        return 10.0\n",
    "    elif row['Cyl'] == '(16 cyl)':\n",
    "        return 16.0\n",
    "    elif row['Cyl'] == '(5 cyl)':\n",
    "        return 5.0\n",
    "    elif row['Cyl'] == '(2 cyl)':\n",
    "        return 2.0\n",
    "    elif row['Cyl'] == '(3 cyl)':\n",
    "        return 3.0\n",
    "    else:\n",
    "        return row['Cyl']\n",
    "    \n",
    "merged_data['Cyl'] = merged_data.apply(convert_cyl, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average(value):\n",
    "    if pd.isna(value):  # Check if value is NaN\n",
    "        return np.nan  # Return NaN if value is NaN\n",
    "    if isinstance(value, str) and '/' in value:\n",
    "        nums = [float(num) for num in value.split('/') if num.isdigit()]\n",
    "        if len(nums) == 0:\n",
    "            return np.nan  # Return NaN if no numeric values are found\n",
    "        return sum(nums) / len(nums)\n",
    "    elif isinstance(value, int) or isinstance(value, float):\n",
    "        return float(value)  # Return value if it's already numeric\n",
    "    else:\n",
    "        return value  # Return NaN for non-numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['Air Pollution Score'] = merged_data['Air Pollution Score'].apply(calculate_average)\n",
    "merged_data['Greenhouse Gas Score'] = merged_data['Greenhouse Gas Score'].apply(calculate_average)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_fuel_records(df):\n",
    "    new_rows = []\n",
    "    for index, row in df.iterrows():\n",
    "        fuel = row['Fuel']\n",
    "        city_mpg = row['City MPG']\n",
    "\n",
    "        # Initialize IsHybrid column with default value\n",
    "        row['IsHybrid'] = 'Not Hybrid'\n",
    "\n",
    "        # Update IsHybrid based on fuel type\n",
    "        if fuel == 'Gasoline/Electricity':\n",
    "            row['IsHybrid'] = 'Electric Hybrid'\n",
    "        elif fuel == 'Ethanol/Gas':\n",
    "            row['IsHybrid'] = 'Ethanol Hybrid'\n",
    "\n",
    "        if ('/' in fuel) and ('/' in city_mpg):\n",
    "            fuels = fuel.split('/')\n",
    "            city_mpgs = city_mpg.split('/')\n",
    "            for i, fuel_type in enumerate(fuels):\n",
    "                new_row = row.copy()\n",
    "                new_row['Fuel'] = fuel_type.strip()\n",
    "                new_row['City MPG'] = city_mpgs[i].strip()\n",
    "                new_rows.append(new_row)\n",
    "        else:\n",
    "            new_rows.append(row)\n",
    "    return pd.DataFrame(new_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = split_fuel_records(merged_data).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Displ                   float64\n",
       "Cyl                     float64\n",
       "Trans                    object\n",
       "Drive                    object\n",
       "Fuel                     object\n",
       "Veh Class                object\n",
       "Air Pollution Score      object\n",
       "City MPG                 object\n",
       "Hwy MPG                  object\n",
       "Cmb MPG                  object\n",
       "Greenhouse Gas Score     object\n",
       "Year                      int64\n",
       "Car_Make                 object\n",
       "Car_Model                object\n",
       "IsHybrid                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#save cleaned data and merged data to CSV\n",
    "merged_data.to_csv('../data/processed/merged_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "categorical_features = [\"Trans\", \n",
    "                        \"Drive\", \n",
    "                        \"Fuel\",\n",
    "                        \"Veh Class\",\n",
    "                        \"Car_Make\", \n",
    "                        \"Car_Model\",\n",
    "                        \"Air Pollution Score\",\n",
    "                        \"Greenhouse Gas Score\"]\n",
    "\n",
    "numerical_features = [\"Displ\",                       \n",
    "                      \"Year\",\n",
    "                      \"Cyl\",\n",
    "                      \"Displ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = merged_data.drop(columns=['City MPG', 'Hwy MPG', 'Cmb MPG'])\n",
    "y = merged_data['City MPG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Encoders require their input argument must be uniformly strings or numbers. Got ['float', 'str']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_encode.py:174\u001b[0m, in \u001b[0;36m_unique_python\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    172\u001b[0m uniques_set, missing_values \u001b[38;5;241m=\u001b[39m _extract_missing(uniques_set)\n\u001b[0;32m--> 174\u001b[0m uniques \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muniques_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m uniques\u001b[38;5;241m.\u001b[39mextend(missing_values\u001b[38;5;241m.\u001b[39mto_list())\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'float'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fit the pipeline on training data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:471\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \n\u001b[1;32m    430\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and sequentially transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    470\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m--> 471\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:408\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, routed_params)\u001b[0m\n\u001b[1;32m    406\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 408\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/memory.py:312\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:1303\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m   1302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1303\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1305\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   1306\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m   1307\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:914\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    912\u001b[0m     routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_empty_routing()\n\u001b[0;32m--> 914\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_func_on_transformers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_fit_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fitted_transformers([])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:823\u001b[0m, in \u001b[0;36mColumnTransformer._call_func_on_transformers\u001b[0;34m(self, X, y, func, column_as_labels, routed_params)\u001b[0m\n\u001b[1;32m    811\u001b[0m             extra_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    812\u001b[0m         jobs\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    813\u001b[0m             delayed(func)(\n\u001b[1;32m    814\u001b[0m                 transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m             )\n\u001b[1;32m    821\u001b[0m         )\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:1303\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m   1302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1303\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1305\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   1306\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m   1307\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:543\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    541\u001b[0m last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(last_step, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlast_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m last_step\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m    548\u001b[0m         Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    549\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1101\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m-> 1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975\u001b[0m, in \u001b[0;36mOneHotEncoder.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    958\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;124;03m    Fit OneHotEncoder to X.\u001b[39;00m\n\u001b[1;32m    960\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;124;03m        Fitted encoder.\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 975\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_drop_idx()\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features_outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_n_features_outs()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:98\u001b[0m, in \u001b[0;36m_BaseEncoder._fit\u001b[0;34m(self, X, handle_unknown, force_all_finite, return_counts, return_and_ignore_missing_for_infrequent)\u001b[0m\n\u001b[1;32m     95\u001b[0m Xi \u001b[38;5;241m=\u001b[39m X_list[i]\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 98\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_counts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compute_counts:\n\u001b[1;32m    100\u001b[0m         cats, counts \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_encode.py:42\u001b[0m, in \u001b[0;36m_unique\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Helper function to find unique values with support for python objects.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03mUses pure python method for object dtype, and numpy method for\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    array. Only provided if `return_counts` is True.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_unique_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_counts\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# numerical\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _unique_np(\n\u001b[1;32m     47\u001b[0m     values, return_inverse\u001b[38;5;241m=\u001b[39mreturn_inverse, return_counts\u001b[38;5;241m=\u001b[39mreturn_counts\n\u001b[1;32m     48\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_encode.py:179\u001b[0m, in \u001b[0;36m_unique_python\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(t\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mtype\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values))\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoders require their input argument must be uniformly \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrings or numbers. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    182\u001b[0m     )\n\u001b[1;32m    183\u001b[0m ret \u001b[38;5;241m=\u001b[39m (uniques,)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_inverse:\n",
      "\u001b[0;31mTypeError\u001b[0m: Encoders require their input argument must be uniformly strings or numbers. Got ['float', 'str']"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline on training data\n",
    "pipeline.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
